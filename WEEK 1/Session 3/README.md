# Tools in Data Science (TDS) – Linux, WSL & LLM Tooling

This document summarizes the third session of the Tools in Data Science (TDS) course, which focused on deeper Linux and WSL concepts, command-line navigation, and setting up tools to interact with Large Language Models (LLMs) directly from the terminal.

---

## Session Details
**Course:** Tools in Data Science (TDS)  
**Session:** Week 1 – Session 3  
**Mode:** Recorded Online Session
(https://www.youtube.com/watch?v=sXlsRhw5X94&feature=youtu.be)

**Focus Area:** Linux file systems, WSL internals, command-line usage, and LLM tooling  

---

## Session Overview
The session built upon previous WSL concepts and provided a detailed understanding of Linux file systems, command-line navigation, and system-level concepts. It also introduced modern developer tooling for interacting with Large Language Models (LLMs) using terminal-based workflows, including environment setup and API configuration.

---

## Topics Covered

### WSL and Computer Boot Process Overview
High-level explanation of how operating systems boot and how WSL integrates with the Windows system architecture.

---

### Understanding Hypervisors
Introduction to hypervisors and how WSL differs from traditional virtual machine–based virtualization.

---

### Navigating the Ubuntu File System in WSL
Understanding Linux directory structure and navigating the Ubuntu file system within WSL.

---

### Absolute vs Relative Paths in Linux
Difference between absolute and relative paths and their usage in command-line navigation.

---

### Comparing Linux and Windows File Systems
Key differences between Linux and Windows file systems, including structure, permissions, and usage patterns.

---

### File System Navigation and Key Directories
Overview of important Linux directories and their roles in system operations.

---

### Q&A: Why Learn Command-Line Tools?
Discussion on the importance of command-line proficiency for Data Science, AI, and software development workflows.

---

### Integrating VS Code Terminal with WSL
Using Visual Studio Code with WSL to create a seamless development environment.

---

### Installing the UV Tool
Introduction to the UV tool and its role in managing Python and development environments.

---

### Installing LLM Tools with UV
Using UV to install tools required for interacting with Large Language Models from the terminal.

---

### Setting Up Gemini API Key
Configuring the Gemini API key to enable interaction with Gemini models.

---

### Setting Up OpenAI & AI-Pipe API Key
Configuring OpenAI and AI-Pipe API keys for accessing GPT-based models.

---

### Using the LLM Command with GPT and Gemini Models
Running LLM commands directly from the terminal to interact with GPT and Gemini models.

---

## Key Learnings
- Gained deeper understanding of Linux file systems and command-line navigation  
- Learned the differences between WSL and traditional virtualization approaches  
- Understood the importance of command-line tools in AI and Data Science workflows  
- Learned how to integrate development tools with WSL for efficient workflows  
- Gained hands-on knowledge of setting up and using LLM tools via terminal commands  

---

## Tools & Concepts Introduced
- Windows Subsystem for Linux (WSL)  
- Ubuntu Linux  
- Linux Command Line Interface  
- Visual Studio Code (WSL Integration)  
- UV Tool  
- LLM Tooling  
- Gemini API  
- OpenAI / AI-Pipe API  

---

## Outcome
This session strengthened foundational Linux and WSL knowledge and introduced modern AI tooling workflows, enabling terminal-based interaction with Large Language Models for practical AI development.


