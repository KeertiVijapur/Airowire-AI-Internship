# Tools in Data Science (TDS) – Introduction to LLM Concepts & RAG

This document summarizes Week 3 – Session 1 of the Tools in Data Science (TDS) course, which introduced the theoretical foundations of Large Language Models (LLMs), embeddings, vector databases, and retrieval-based AI systems.

---

## Session Details
**Course:** Tools in Data Science (TDS)  
**Session:** Week 3 – Session 1  
**Mode:** Recorded Online Session
(https://youtu.be/s-ZQ2I1lE7Y)

**Focus Area:** LLM architecture, embeddings, vector databases, and Retrieval Augmented Generation (RAG)

---

## Session Overview
This session shifted focus from tooling and deployment to core Artificial Intelligence concepts. It explained how Large Language Models work internally, including tokens, transformers, attention mechanisms, and context handling. The session also introduced embeddings, vector databases, and RAG pipelines, which form the foundation of modern AI applications such as chatbots, search assistants, and AI agents.

---

## Topics Covered

### API Keys and Proxy Usage
Understanding secure API access and proxy routing for AI services.

---

### How LLMs Work
Overview of tokens, transformer architecture, and prediction-based text generation.

---

### Self Attention Mechanism
Understanding how models focus on relevant words in a sentence to generate context-aware responses.

---

### Context Limitations of LLMs
Why models have token limits and how it affects long conversations.

---

### Embeddings
Converting text into numerical vector representations for semantic understanding.

---

### Topic Modeling
Grouping similar documents or ideas using statistical patterns.

---

### Vector Databases
Storing and retrieving embeddings efficiently for similarity search.

---

### Retrieval Augmented Generation (RAG)
Combining retrieval systems with LLMs to provide accurate and grounded responses.

---

### Hybrid RAG
Using multiple retrieval strategies for improved answer quality.

---

### Base64 Encoding
Encoding binary data for safe transmission in APIs.

---

### Vision Models
Processing images using AI models.

---

### Prompt Engineering
Designing effective prompts to guide LLM outputs.

---

### Sentiment Analysis & Text Extraction
Extracting meaning and structured information from text data.

---

### Agents & Tool Usage
Using LLMs with external tools and APIs to perform tasks.

---

### LLM Evaluation & Testing
Measuring model performance and validating outputs.

---

## Key Learnings
- Understood the internal working of Large Language Models  
- Learned importance of embeddings and semantic search  
- Gained knowledge of vector databases and RAG pipelines  
- Learned prompt engineering fundamentals  
- Understood how AI agents use tools and APIs  

---

## Tools & Concepts Introduced
- Transformers  
- Tokens  
- Embeddings  
- Vector Databases  
- Retrieval Augmented Generation (RAG)  
- Prompt Engineering  
- AI Agents  
- LLM Evaluation  

---

## Outcome
This session built the conceptual foundation required to design intelligent AI systems that can retrieve, reason, and generate meaningful responses using modern LLM architectures.
